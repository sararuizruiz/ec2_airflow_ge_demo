[2021-02-01 08:43:50,278] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: ge_quarantine_df_dag.import_monthly_data 2021-01-30T14:55:44.834581+00:00 [queued]>
[2021-02-01 08:43:50,288] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: ge_quarantine_df_dag.import_monthly_data 2021-01-30T14:55:44.834581+00:00 [queued]>
[2021-02-01 08:43:50,288] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2021-02-01 08:43:50,288] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2021-02-01 08:43:50,288] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2021-02-01 08:43:50,300] {taskinstance.py:1038} INFO - Executing <Task(SnowflakeOperator): import_monthly_data> on 2021-01-30T14:55:44.834581+00:00
[2021-02-01 08:43:50,304] {standard_task_runner.py:51} INFO - Started process 4520 to run task
[2021-02-01 08:43:50,312] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'ge_quarantine_df_dag', 'import_monthly_data', '2021-01-30T14:55:44.834581+00:00', '--job-id', '202', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/ge_quarantine_df_dag.py', '--cfg-path', '/var/folders/s2/xy3ssc8j3ks3whp2f_b8708c0000gp/T/tmpgmtxkjhw']
[2021-02-01 08:43:50,314] {standard_task_runner.py:76} INFO - Job 202: Subtask import_monthly_data
[2021-02-01 08:43:50,357] {logging_mixin.py:103} INFO - Running <TaskInstance: ge_quarantine_df_dag.import_monthly_data 2021-01-30T14:55:44.834581+00:00 [running]> on host 1.0.0.127.in-addr.arpa
[2021-02-01 08:43:50,407] {taskinstance.py:1230} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=sara@acloudfrontier.com
AIRFLOW_CTX_DAG_OWNER=sara
AIRFLOW_CTX_DAG_ID=ge_quarantine_df_dag
AIRFLOW_CTX_TASK_ID=import_monthly_data
AIRFLOW_CTX_EXECUTION_DATE=2021-01-30T14:55:44.834581+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-30T14:55:44.834581+00:00
[2021-02-01 08:43:50,408] {snowflake.py:119} INFO - Executing: ['put file:////Users/sara/airflow/dags/local/yellow_tripdata_sample_2019-03.csv @%monthly_data;', "copy into monthly_data from '@%monthly_data/yellow_tripdata_sample_2019-03.csv.gz' ;", 'alter table MONTHLY_DATA add column error integer;']
[2021-02-01 08:43:50,419] {base.py:65} INFO - Using connection to: id: SNOWFLAKE_QUARANTINE_DEMO. Host: dp13486.eu-west-1.snowflakecomputing.com, Port: None, Schema: PUBLIC, Login: SARA, Password: XXXXXXXX, extra: XXXXXXXX
[2021-02-01 08:43:50,423] {connection.py:215} INFO - Snowflake Connector for Python Version: 2.3.9, Python Version: 3.8.6, Platform: macOS-10.16-x86_64-i386-64bit
[2021-02-01 08:43:50,425] {connection.py:768} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2021-02-01 08:43:50,425] {connection.py:784} INFO - Setting use_openssl_only mode to False
[2021-02-01 08:43:54,393] {cursor.py:537} INFO - query: [ALTER SESSION SET autocommit=True]
[2021-02-01 08:43:55,603] {cursor.py:560} INFO - query execution done
[2021-02-01 08:43:55,604] {dbapi.py:180} INFO - Running statement: put file:////Users/sara/airflow/dags/local/yellow_tripdata_sample_2019-03.csv @%monthly_data;, parameters: None
[2021-02-01 08:43:55,604] {cursor.py:537} INFO - query: [put file:////Users/sara/airflow/dags/local/yellow_tripdata_sample_2019-03.csv @%...]
[2021-02-01 08:43:56,824] {cursor.py:560} INFO - query execution done
[2021-02-01 08:44:04,729] {dbapi.py:186} INFO - Rows affected: 1
[2021-02-01 08:44:04,731] {dbapi.py:180} INFO - Running statement: copy into monthly_data from '@%monthly_data/yellow_tripdata_sample_2019-03.csv.gz' ;, parameters: None
[2021-02-01 08:44:04,731] {cursor.py:537} INFO - query: [copy into monthly_data from '@%monthly_data/yellow_tripdata_sample_2019-03.csv.g...]
[2021-02-01 08:44:06,433] {cursor.py:560} INFO - query execution done
[2021-02-01 08:44:06,434] {dbapi.py:186} INFO - Rows affected: 1
[2021-02-01 08:44:06,434] {dbapi.py:180} INFO - Running statement: alter table MONTHLY_DATA add column error integer;, parameters: None
[2021-02-01 08:44:06,436] {cursor.py:537} INFO - query: [alter table MONTHLY_DATA add column error integer;]
[2021-02-01 08:44:07,332] {cursor.py:560} INFO - query execution done
[2021-02-01 08:44:07,361] {connection.py:438} INFO - closed
[2021-02-01 08:44:08,175] {connection.py:441} INFO - No async queries seem to be running, deleting session
[2021-02-01 08:44:09,089] {taskinstance.py:1396} ERROR - 001430 (42601): 0199feb0-0047-ca48-0000-a011000426d2: SQL compilation error:
column 'ERROR' already exists
Traceback (most recent call last):
  File "/Users/sara/p38_demo_env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1086, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/Users/sara/p38_demo_env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1260, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/Users/sara/p38_demo_env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1300, in _execute_task
    result = task_copy.execute(context=context)
  File "/Users/sara/p38_demo_env/lib/python3.8/site-packages/airflow/providers/snowflake/operators/snowflake.py", line 121, in execute
    hook.run(self.sql, autocommit=self.autocommit, parameters=self.parameters)
  File "/Users/sara/p38_demo_env/lib/python3.8/site-packages/airflow/hooks/dbapi.py", line 184, in run
    cur.execute(sql_statement)
  File "/Users/sara/p38_demo_env/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 612, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/Users/sara/p38_demo_env/lib/python3.8/site-packages/snowflake/connector/errors.py", line 224, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/Users/sara/p38_demo_env/lib/python3.8/site-packages/snowflake/connector/errors.py", line 179, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001430 (42601): 0199feb0-0047-ca48-0000-a011000426d2: SQL compilation error:
column 'ERROR' already exists
[2021-02-01 08:44:09,093] {taskinstance.py:1433} INFO - Marking task as FAILED. dag_id=ge_quarantine_df_dag, task_id=import_monthly_data, execution_date=20210130T145544, start_date=20210201T074350, end_date=20210201T074409
[2021-02-01 08:44:09,179] {local_task_job.py:118} INFO - Task exited with return code 1
